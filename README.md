# TopicMind: Key Topic Identification and Summarization

TopicMind is an NLP system designed to identify the main topics within extensive text collections (like Reddit threads) and generate concise, topic-focused summaries. It helps users quickly grasp the core ideas buried in lengthy discussions by filtering out noise and highlighting essential themes.

## Problem Solved

Addresses the challenge of information overload in large text datasets (e.g., online forums, articles) by automatically extracting key topics and providing summaries for each, saving users time and effort.

## Features

*   **Topic Detection:** Uncovers latent themes in text using:
    *   Latent Dirichlet Allocation (LDA) for messy, user-generated content (refined with LLM assistance).
    *   BERT classification for cleaner, pre-labeled data.
*   **Topic-Based Summarization:** Generates abstractive summaries focused on specific identified topics using a BART-based model.
*   **Web Interface:** Provides a simple interface (built with Streamlit) to input text and view the analysis results.

## Tech Stack

*   **Backend:** Python, Flask
*   **NLP/ML:** scikit-learn (for LDA), transformers (for BART, potentially BERT), NLTK/spaCy (for preprocessing), OpenAI API (for topic refinement)
*   **Frontend:** Streamlit
*   **Data:** Primarily Reddit comment datasets.

_(Note: Specific libraries based on common implementations; please update `requirements.txt` as needed)_.

## Project Structure

```
topicMind/
├── .git/               # Git repository data
├── .gitignore          # Files ignored by Git
├── README.md           # This file
├── topicmind/          # Main application package
│   ├── __init__.py
│   ├── app.py          # Flask application (if used)
│   ├── data/           # Data files (e.g., sample JSON)
│   ├── frontend/       # Streamlit UI code (streamlit_app.py)
│   ├── models/         # ML models (LDA, BART)
│   ├── prompts/        # Prompts for LLM refinement
│   ├── utils/          # Utility scripts (preprocessing, refinement logic)
│   └── requirements.txt # Project dependencies
```

## Frontend Interface (Streamlit)

This section outlines the expected inputs and outputs for the Streamlit frontend located in `topicmind/frontend/streamlit_app.py`.

**Input:**

1.  **Primary Input:**
    *   **Text Data:** A main text area for pasting large blocks of text (e.g., forum threads, articles).
    *   **(Future):** *File Upload:* Capability to upload `.txt`, `.csv`, or `.json` files. Define expected structure (e.g., specific column for text).
2.  **Configuration Parameters (Optional):**
    *   *Number of Topics:* Input (slider/number field) to suggest topic count for LDA. (Default: 5 or auto).
    *   *(Future):* *Model Selection:* Dropdown/radio buttons to choose between analysis methods (e.g., LDA for messy text, BERT for cleaner data).

**Output:**

1.  **Identified Topics:**
    *   Display a list of identified topic labels (e.g., "Topic 1: Technology Trends"). Labels should be meaningful (keywords from LDA or LLM-refined).
2.  **Topic Summaries:**
    *   Show the concise, abstractive summary generated by BART for each corresponding topic label.
3.  **Visualization (Future):**
    *   *Topic Prevalence:* Bar chart showing relative weight/importance of each topic.
    *   *Word Clouds:* Visual representation of key terms for each topic.
4.  **Processing Status:**
    *   Display feedback messages during analysis (e.g., "Preprocessing...", "Modeling topics...", "Summarizing...").
    *   Provide clear error messages if the process fails.

## Current Status (as of April 10, 2025)

*   **End-to-End Functionality:** The system now runs end-to-end: text can be input via the Streamlit UI, sent to the Flask backend, processed through preprocessing, LDA topic assignment, and BART summarization, and results (topics and summaries) are displayed back in the UI.
*   **Component Integration:** Preprocessing (`utils/preprocessor.py`), NLTK sentence splitting, LDA topic assignment (`models/lda_topic_model.py`), BART summarization (`models/bart_summarizer.py`), and placeholder LLM topic refinement (`utils/topic_refiner.py`) are integrated into the Flask backend (`app.py`).
*   **Frontend:** A functional Streamlit interface (`frontend/streamlit_app.py`) exists for user interaction.
*   **LDA Model Training:** A script (`models/lda_topic_model.py`) exists to train the LDA model and save necessary files (`.pkl`). It was successfully run on the sample data after installing required NLTK resources.
*   **Environment Setup:** Dependency management (`requirements.txt`) is in place, and environment variable loading (`.env` via `python-dotenv`) is implemented.

*   **Key Issues Identified:**
    *   **LDA Model Quality:** The current LDA model, trained only on 5 irrelevant sample documents (`data/reddit_sample.json`), produces nonsensical topics and keyword lists when applied to different input text (e.g., Pokémon). This is the primary blocker for meaningful results.
    *   **LLM Topic Refinement:** The OpenAI API integration for refining topic names is **not working**. Logs show `OpenAI client not initialized. Cannot refine topic name.`, preventing meaningful topic labels from being generated.
    *   **Summary Quality:** While the BART summarizer functions, the summaries are based on sentences grouped under the irrelevant LDA topics, making the summaries themselves less useful.

## Getting Started

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/SaiKrishna-KK/topic-mind.git
    cd topicMind
    ```
2.  **Create and activate a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```
3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    _(You might need to install additional libraries like `transformers`, `torch`, `nltk`, `openai`, `scikit-learn` if not already included in requirements.txt)_.

4.  **Run the Streamlit application:**
    ```bash
    streamlit run frontend/streamlit_app.py
    ```

## Usage

1.  Navigate to the Streamlit URL provided after running the command above.
2.  Paste the text you want to analyze into the input text area.
3.  Click the "Analyze" button.
4.  View the identified topics and their corresponding summaries.

## Team

*   Sai Krishna Vishnumolakala (Pipeline Integration)
*   Harsha Reddy Palapala (Data Collection & Cleaning)
*   Gagana Vivekananda (LDA Implementation)
*   Bhavitha Kakumanu (BART Summarizer Fine-tuning)
*   Balakrishna Mangala (Evaluation & Testing)

## TODOs / Future Work (Revised April 10, 2025)

**Immediate Priorities:**

1.  **Retrain LDA Model (Critical):**
    *   Acquire or curate a larger, relevant dataset suitable for the intended use case of TopicMind (e.g., diverse Reddit discussions).
    *   Retrain the LDA model using `models/lda_topic_model.py` on this new dataset.
    *   Verify preprocessing consistency between training and inference.
2.  **Fix OpenAI Integration (Critical):**
    *   Debug the OpenAI client initialization in `utils/topic_refiner.py`.
    *   Ensure the API key loaded from `.env` is correctly passed to and utilized by the `openai` library client.
    *   Confirm successful API calls for topic refinement.

**Next Steps:**

*   **Evaluation:** Implement and run quantitative evaluation:
    *   Topic Coherence (e.g., C\_v) for the retrained LDA model.
    *   ROUGE scores for the generated summaries against reference summaries (if available) or qualitative assessment.
*   **Preprocessing Review:** Double-check and ensure consistency in text cleaning and stopword handling between LDA training and the main application pipeline (`app.py`).
*   **Error Handling:** Enhance error handling and logging within `app.py` and utility scripts for better robustness and easier debugging.

**Future Enhancements:**

*   Implement the optional BERT classification pathway for topic modeling on cleaner datasets.
*   Fine-tune the BART summarizer model for improved focus on the identified topics.
*   Improve the Streamlit UI, possibly adding visualizations (topic prevalence, word clouds) or user configuration options.
*   Conduct thorough testing across various datasets and edge cases.
*   Expand dataset usage beyond the initial retraining set. 